{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Battery Offloading Simulation Analysis\n",
    "\n",
    "This notebook provides template analysis for battery offloading simulation results.\n",
    "It automatically loads the latest simulation results and generates comprehensive visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure matplotlib for better plots\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Latest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_results(base_dir=\"../results\"):\n",
    "    \"\"\"\n",
    "    Find the most recent simulation results directory.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (results_dir, per_task_file, summary_file)\n",
    "    \"\"\"\n",
    "    results_path = Path(base_dir)\n",
    "    if not results_path.exists():\n",
    "        results_path = Path(\"../src/results\")\n",
    "    \n",
    "    # Find all timestamp directories\n",
    "    timestamp_dirs = []\n",
    "    for item in results_path.iterdir():\n",
    "        if item.is_dir() and item.name.replace('_', '').replace('-', '').isdigit():\n",
    "            timestamp_dirs.append(item)\n",
    "    \n",
    "    if not timestamp_dirs:\n",
    "        raise FileNotFoundError(\"No simulation results found in results directory\")\n",
    "    \n",
    "    # Get the most recent directory\n",
    "    latest_dir = max(timestamp_dirs, key=lambda x: x.name)\n",
    "    \n",
    "    # Look for CSV files\n",
    "    per_task_file = latest_dir / \"per_task_results.csv\"\n",
    "    summary_file = latest_dir / \"summary_statistics.csv\"\n",
    "    \n",
    "    if not per_task_file.exists():\n",
    "        raise FileNotFoundError(f\"per_task_results.csv not found in {latest_dir}\")\n",
    "    if not summary_file.exists():\n",
    "        raise FileNotFoundError(f\"summary_statistics.csv not found in {latest_dir}\")\n",
    "    \n",
    "    return latest_dir, per_task_file, summary_file\n",
    "\n",
    "# Load the latest results\n",
    "try:\n",
    "    results_dir, per_task_file, summary_file = find_latest_results()\n",
    "    print(f\"Loading results from: {results_dir}\")\n",
    "    \n",
    "    # Load the data\n",
    "    per_task_df = pd.read_csv(per_task_file)\n",
    "    summary_df = pd.read_csv(summary_file)\n",
    "    \n",
    "    print(f\"Loaded {len(per_task_df)} task records\")\n",
    "    print(f\"Summary: {len(summary_df)} metrics\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading results: {e}\")\n",
    "    print(\"Please run a simulation first or check the results directory path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the data\n",
    "if 'per_task_df' in locals():\n",
    "    print(\"Per-task data columns:\")\n",
    "    print(per_task_df.columns.tolist())\n",
    "    print(\"\\nFirst few rows of per-task data:\")\n",
    "    display(per_task_df.head())\n",
    "    \n",
    "    print(\"\\nSummary statistics:\")\n",
    "    display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Latency Distribution Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latency_distribution(per_task_df, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot histogram of task latency distribution.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Convert latency to milliseconds if needed\n",
    "    if 'latency_ms' in per_task_df.columns:\n",
    "        latency_data = per_task_df['latency_ms']\n",
    "        unit = 'ms'\n",
    "    elif 'total_latency_s' in per_task_df.columns:\n",
    "        latency_data = per_task_df['total_latency_s'] * 1000  # Convert to ms\n",
    "        unit = 'ms'\n",
    "    else:\n",
    "        print(\"Warning: No latency column found\")\n",
    "        return\n",
    "    \n",
    "    # Create histogram with execution site coloring\n",
    "    if 'execution_site' in per_task_df.columns:\n",
    "        sites = per_task_df['execution_site'].unique()\n",
    "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Blue, Orange, Green\n",
    "        \n",
    "        for i, site in enumerate(sites):\n",
    "            site_data = per_task_df[per_task_df['execution_site'] == site]\n",
    "            ax.hist(site_data[latency_data.name], bins=20, alpha=0.7, \n",
    "                   label=f'{site} ({len(site_data)} tasks)', \n",
    "                   color=colors[i % len(colors)])\n",
    "    else:\n",
    "        ax.hist(latency_data, bins=20, alpha=0.7, color='#1f77b4')\n",
    "    \n",
    "    ax.set_xlabel(f'Task Latency ({unit})')\n",
    "    ax.set_ylabel('Number of Tasks')\n",
    "    ax.set_title('Task Latency Distribution by Execution Site')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add statistics text\n",
    "    mean_latency = latency_data.mean()\n",
    "    p95_latency = latency_data.quantile(0.95)\n",
    "    ax.axvline(mean_latency, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_latency:.1f}{unit}')\n",
    "    ax.axvline(p95_latency, color='orange', linestyle='--', alpha=0.7, label=f'P95: {p95_latency:.1f}{unit}')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Latency distribution plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Generate the plot\n",
    "if 'per_task_df' in locals():\n",
    "    plot_latency_distribution(per_task_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Battery SoC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_soc_curve(per_task_df, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot battery State of Charge (SoC) over time.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Check for SoC columns\n",
    "    if 'soc_after' in per_task_df.columns and 'completion_time_s' in per_task_df.columns:\n",
    "        time_data = per_task_df['completion_time_s']\n",
    "        soc_data = per_task_df['soc_after']\n",
    "        \n",
    "        # Add initial point (assuming we start at some initial SoC)\n",
    "        if 'soc_before' in per_task_df.columns and len(per_task_df) > 0:\n",
    "            initial_soc = per_task_df.iloc[0]['soc_before']\n",
    "            time_data = [0] + time_data.tolist()\n",
    "            soc_data = [initial_soc] + soc_data.tolist()\n",
    "        \n",
    "        ax.plot(time_data, soc_data, 'b-', linewidth=2, marker='o', markersize=4)\n",
    "        \n",
    "        # Add execution site markers\n",
    "        if 'execution_site' in per_task_df.columns:\n",
    "            colors = {'LOCAL': 'blue', 'EDGE': 'orange', 'CLOUD': 'green'}\n",
    "            for site, color in colors.items():\n",
    "                site_mask = per_task_df['execution_site'] == site\n",
    "                if site_mask.any():\n",
    "                    ax.scatter(per_task_df[site_mask]['completion_time_s'], \n",
    "                              per_task_df[site_mask]['soc_after'],\n",
    "                              c=color, s=50, alpha=0.7, label=f'{site} tasks')\n",
    "        \n",
    "        ax.set_xlabel('Time (seconds)')\n",
    "        ax.set_ylabel('Battery SoC (%)')\n",
    "        ax.set_title('Battery State of Charge Over Time')\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.legend()\n",
    "        \n",
    "        # Add grid for better readability\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'SoC data not available\\nColumns needed: soc_after, completion_time_s', \n",
    "                transform=ax.transAxes, ha='center', va='center', fontsize=14)\n",
    "        ax.set_title('Battery SoC Curve (No Data Available)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"SoC curve plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Generate the plot\n",
    "if 'per_task_df' in locals():\n",
    "    plot_soc_curve(per_task_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Energy Consumption Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy_boxplot(per_task_df, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot box plot of energy consumption by execution site.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Check for energy and execution site columns\n",
    "    energy_col = None\n",
    "    for col in ['energy_wh', 'total_energy_wh', 'energy_consumed_wh']:\n",
    "        if col in per_task_df.columns:\n",
    "            energy_col = col\n",
    "            break\n",
    "    \n",
    "    if energy_col and 'execution_site' in per_task_df.columns:\n",
    "        # Prepare data for box plot\n",
    "        sites = per_task_df['execution_site'].unique()\n",
    "        energy_by_site = [per_task_df[per_task_df['execution_site'] == site][energy_col].values \n",
    "                         for site in sites]\n",
    "        \n",
    "        # Create box plot\n",
    "        box_plot = ax.boxplot(energy_by_site, labels=sites, patch_artist=True)\n",
    "        \n",
    "        # Color the boxes\n",
    "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Blue, Orange, Green\n",
    "        for patch, color in zip(box_plot['boxes'], colors[:len(sites)]):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.7)\n",
    "        \n",
    "        ax.set_xlabel('Execution Site')\n",
    "        ax.set_ylabel('Energy Consumption (Wh)')\n",
    "        ax.set_title('Energy Consumption Distribution by Execution Site')\n",
    "        \n",
    "        # Add statistics annotations\n",
    "        for i, site in enumerate(sites):\n",
    "            site_data = per_task_df[per_task_df['execution_site'] == site][energy_col]\n",
    "            mean_energy = site_data.mean()\n",
    "            ax.text(i+1, mean_energy, f'{mean_energy:.4f}', ha='center', \n",
    "                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
    "        \n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f'Energy data not available\\nColumns needed: energy_wh, execution_site\\nAvailable: {list(per_task_df.columns)}', \n",
    "                transform=ax.transAxes, ha='center', va='center', fontsize=12)\n",
    "        ax.set_title('Energy Consumption Box Plot (No Data Available)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Energy box plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Generate the plot\n",
    "if 'per_task_df' in locals():\n",
    "    plot_energy_boxplot(per_task_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Execution Site Distribution Pie Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_execution_site_pie(per_task_df, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot pie chart showing distribution of tasks across execution sites.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Execution Site Distribution\n",
    "    if 'execution_site' in per_task_df.columns:\n",
    "        site_counts = per_task_df['execution_site'].value_counts()\n",
    "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Blue, Orange, Green\n",
    "        \n",
    "        wedges, texts, autotexts = ax1.pie(site_counts.values, \n",
    "                                          labels=site_counts.index,\n",
    "                                          colors=colors[:len(site_counts)],\n",
    "                                          autopct='%1.1f%%',\n",
    "                                          startangle=90)\n",
    "        \n",
    "        ax1.set_title('Task Distribution by Execution Site')\n",
    "        \n",
    "        # Add count annotations\n",
    "        for i, (label, count) in enumerate(site_counts.items()):\n",
    "            ax1.text(0, -1.3 - i*0.1, f'{label}: {count} tasks', \n",
    "                    transform=ax1.transData, ha='center')\n",
    "    else:\n",
    "        ax1.text(0.5, 0.5, 'Execution site data\\nnot available', \n",
    "                transform=ax1.transAxes, ha='center', va='center')\n",
    "        ax1.set_title('Execution Site Distribution (No Data)')\n",
    "    \n",
    "    # Task Type Distribution\n",
    "    if 'task_type' in per_task_df.columns:\n",
    "        type_counts = per_task_df['task_type'].value_counts()\n",
    "        colors = ['#d62728', '#9467bd', '#8c564b']  # Red, Purple, Brown\n",
    "        \n",
    "        wedges, texts, autotexts = ax2.pie(type_counts.values,\n",
    "                                          labels=type_counts.index,\n",
    "                                          colors=colors[:len(type_counts)],\n",
    "                                          autopct='%1.1f%%',\n",
    "                                          startangle=90)\n",
    "        \n",
    "        ax2.set_title('Task Distribution by Task Type')\n",
    "        \n",
    "        # Add count annotations\n",
    "        for i, (label, count) in enumerate(type_counts.items()):\n",
    "            ax2.text(0, -1.3 - i*0.1, f'{label}: {count} tasks', \n",
    "                    transform=ax2.transData, ha='center')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'Task type data\\nnot available', \n",
    "                transform=ax2.transAxes, ha='center', va='center')\n",
    "        ax2.set_title('Task Type Distribution (No Data)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Distribution pie charts saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Generate the plot\n",
    "if 'per_task_df' in locals():\n",
    "    plot_execution_site_pie(per_task_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Task Timeline Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_task_timeline(per_task_df, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot task execution timeline with different colors for execution sites.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    if 'arrival_time_s' in per_task_df.columns and 'completion_time_s' in per_task_df.columns:\n",
    "        # Color mapping for execution sites\n",
    "        color_map = {'LOCAL': '#1f77b4', 'EDGE': '#ff7f0e', 'CLOUD': '#2ca02c'}\n",
    "        \n",
    "        # Plot each task as a horizontal bar\n",
    "        for i, row in per_task_df.iterrows():\n",
    "            start_time = row['arrival_time_s']\n",
    "            end_time = row['completion_time_s']\n",
    "            site = row.get('execution_site', 'UNKNOWN')\n",
    "            color = color_map.get(site, '#cccccc')\n",
    "            \n",
    "            ax.barh(i, end_time - start_time, left=start_time, \n",
    "                   color=color, alpha=0.7, height=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Time (seconds)')\n",
    "        ax.set_ylabel('Task ID')\n",
    "        ax.set_title('Task Execution Timeline by Site')\n",
    "        \n",
    "        # Create legend\n",
    "        legend_elements = [plt.Rectangle((0,0),1,1, facecolor=color, alpha=0.7, label=site) \n",
    "                          for site, color in color_map.items()]\n",
    "        ax.legend(handles=legend_elements)\n",
    "        \n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'Timeline data not available\\nColumns needed: arrival_time_s, completion_time_s', \n",
    "                transform=ax.transAxes, ha='center', va='center', fontsize=14)\n",
    "        ax.set_title('Task Timeline (No Data Available)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Task timeline plot saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Generate the plot\n",
    "if 'per_task_df' in locals():\n",
    "    plot_task_timeline(per_task_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_statistics(per_task_df, summary_df):\n",
    "    \"\"\"\n",
    "    Print comprehensive summary statistics.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SIMULATION SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Basic statistics\n",
    "    total_tasks = len(per_task_df)\n",
    "    print(f\"Total Tasks: {total_tasks}\")\n",
    "    \n",
    "    if 'execution_site' in per_task_df.columns:\n",
    "        print(\"\\nExecution Site Distribution:\")\n",
    "        site_counts = per_task_df['execution_site'].value_counts()\n",
    "        for site, count in site_counts.items():\n",
    "            print(f\"  {site}: {count} ({count/total_tasks*100:.1f}%)\")\n",
    "    \n",
    "    if 'task_type' in per_task_df.columns:\n",
    "        print(\"\\nTask Type Distribution:\")\n",
    "        type_counts = per_task_df['task_type'].value_counts()\n",
    "        for task_type, count in type_counts.items():\n",
    "            print(f\"  {task_type}: {count} ({count/total_tasks*100:.1f}%)\")\n",
    "    \n",
    "    # Latency statistics\n",
    "    latency_col = None\n",
    "    for col in ['latency_ms', 'total_latency_s']:\n",
    "        if col in per_task_df.columns:\n",
    "            latency_col = col\n",
    "            break\n",
    "    \n",
    "    if latency_col:\n",
    "        latency_data = per_task_df[latency_col]\n",
    "        if latency_col == 'total_latency_s':\n",
    "            latency_data = latency_data * 1000  # Convert to ms\n",
    "            unit = 'ms'\n",
    "        else:\n",
    "            unit = 'ms'\n",
    "            \n",
    "        print(f\"\\nLatency Statistics ({unit}):\")\n",
    "        print(f\"  Mean: {latency_data.mean():.2f}\")\n",
    "        print(f\"  Median: {latency_data.median():.2f}\")\n",
    "        print(f\"  P95: {latency_data.quantile(0.95):.2f}\")\n",
    "        print(f\"  P99: {latency_data.quantile(0.99):.2f}\")\n",
    "        print(f\"  Min: {latency_data.min():.2f}\")\n",
    "        print(f\"  Max: {latency_data.max():.2f}\")\n",
    "    \n",
    "    # Energy statistics\n",
    "    energy_col = None\n",
    "    for col in ['energy_wh', 'total_energy_wh', 'energy_consumed_wh']:\n",
    "        if col in per_task_df.columns:\n",
    "            energy_col = col\n",
    "            break\n",
    "    \n",
    "    if energy_col:\n",
    "        energy_data = per_task_df[energy_col]\n",
    "        print(f\"\\nEnergy Statistics (Wh):\")\n",
    "        print(f\"  Total: {energy_data.sum():.6f}\")\n",
    "        print(f\"  Mean per task: {energy_data.mean():.6f}\")\n",
    "        print(f\"  Std dev: {energy_data.std():.6f}\")\n",
    "    \n",
    "    # Battery statistics\n",
    "    if 'soc_after' in per_task_df.columns:\n",
    "        initial_soc = per_task_df.iloc[0].get('soc_before', per_task_df['soc_after'].max())\n",
    "        final_soc = per_task_df['soc_after'].iloc[-1]\n",
    "        print(f\"\\nBattery Statistics (%):\")\n",
    "        print(f\"  Initial SoC: {initial_soc:.2f}\")\n",
    "        print(f\"  Final SoC: {final_soc:.2f}\")\n",
    "        print(f\"  SoC Drop: {initial_soc - final_soc:.2f}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Print summary\n",
    "if 'per_task_df' in locals() and 'summary_df' in locals():\n",
    "    print_summary_statistics(per_task_df, summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save All Plots\n",
    "\n",
    "This section saves all plots to a figures directory within the results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures directory and save all plots\n",
    "if 'results_dir' in locals():\n",
    "    figures_dir = results_dir / \"figures\"\n",
    "    figures_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"Saving all plots to: {figures_dir}\")\n",
    "    \n",
    "    # Generate and save all plots\n",
    "    plot_latency_distribution(per_task_df, figures_dir / \"latency_distribution.png\")\n",
    "    plot_soc_curve(per_task_df, figures_dir / \"soc_curve.png\")\n",
    "    plot_energy_boxplot(per_task_df, figures_dir / \"energy_boxplot.png\")\n",
    "    plot_execution_site_pie(per_task_df, figures_dir / \"distribution_pies.png\")\n",
    "    plot_task_timeline(per_task_df, figures_dir / \"task_timeline.png\")\n",
    "    \n",
    "    print(\"\\nAll plots saved successfully!\")\n",
    "else:\n",
    "    print(\"No results directory found. Please load results first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}